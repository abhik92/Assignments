\documentclass[12pt]{exam}
\printanswers
\usepackage{amsmath,amssymb,complexity}
\begin{document}
\hrule
\vspace{3mm}
\noindent 
{\sf CS6014 : Advanced Theory of Computation  \hfill Karthik Abinav S}
\vspace{3mm}\\
\noindent 
{\sf Problem Set \#6 }
\vspace{3mm}
\hrule

\begin{questions}

\question[10] Oracle Queries.
\begin{parts}
\part Argue that $\P^\P = \P$. Why does not the same argument work for $\NP$ and give $\NP^{\NP} = \NP$?
\part If $\NP = \co\NP$, argue that $\PH = \Sigma_1^p$.
\end{parts}
\begin{solution}
\begin{parts}
 
\part
 $\P^\P \subseteq P $ \newline
 Let $L \in \P^\P$ . There exists an oracle TM $N$ such that, it runs in polynomial time and has access to a language in $P$ as an oracle. This
 can be simulated by deterministic polynomial time machine $M$ without the oracle as follows : \newline
 
 $M$ runs on the input in the same way as $N$. Except whenever $N$ makes query to the oracle to check if $x \in K$ where $K$ is the oracle, $M$ runs
 the machine corresponding to the oracle language on $x$ and gets the answer. It then proceeds in the similar way as the machine $N$. Since the oracle is a 
 language in $\P$, the simulation of the query to oracle takes deterministic polynomial time. Hence , $M$ runs in polynomial time.
 
 $\P \subseteq \P^\P$ \newline
 This containment is trivially true, since the machine accepting $\P$ need not use the oracle and hence belongs to $\P^\P$ \newline
 
 From above two containments, $\P^\P = \P$ \newline
 
 The above argument wont work for $\NP$ because, when the oracle gives the answer as no, the same thing cannot be determined by simulating a 
 $\NP$ machine in polynomial time. Since , the time for a non deterministic machine is defined as the length of the shortest accepting path. Hence,the rejecting
 paths in the non deterministic tree may not be of polynomial length. \newline

 \part
 This can be shown using induction on $i$ of $\Sigma_{i}^{P}$ .\newline
 Base case. $i$ = 2. \newline
 we have to show $\NP^\NP = \NP$.
 The reverse containment is trivially true. To show the forward containment, we can simulate the queries on the oracle by simulating the two non deterministic
 machines corresponding to $L$(say $M$) and $\overline{L}$(say $N$) . There exists a non deterministic polynomial time machine for $\overline{L}$ because $\NP$ = $\co\NP$. \newline
 Whenever the original machine made a query to oracle, simulate both the non deterministic machine in time sharing fashion. If $M$ accepts, interpret as a yes answer by
 the oracle and continue calculation as the original machine. If $N$ accepts, interpret as a no answer by the oracle and continue calculation as the original machine.
 Since, both $M$ and $N$ accepts in poylnomial time, this new machine also runs in polynomial time. Hence, $\Sigma_{2}^{P}$ = $\Sigma_{1}^{P}$. \newline
 
 Let for some $k > 2$, $\Sigma_{k}^{P} = \Sigma_{1}^{P}$.\newline
 $\Sigma_{k+1}^{P}$ is language which can be accepted in $\NP$ time given an oracle to $\Sigma_{k}^{P}$. Since, from induction hypothesis, $\Sigma_{k}^{P}$
  = $\Sigma_{1}^{P}$, this can be accepted by a machine in $\NP$ time which has oracle access to $\NP$. Similar to the above case, let $M$ be a machine
  which accepts the language corresponding to $L \in \NP$ and $\overline{L} \in \co\NP$ . Now, the oracle query can be replaced by simulating both the machines
  in a time sharing manner. If $M$ accepts, interpret as a yes answer from oracle. If $N$ accepts, interpret as a no answer from oracle. Then continue
  computation normally as the oracle machine from there. Since, both $M$ and $N$ accepts in polynomial time, hence the entire simulation can be done in $\NP$ time.
  Therefore, $\Sigma_{k+1}^{P}$ = $\Sigma_{1}^{P}$.
 \end{parts}
\end{solution}


\question[10]
\begin{parts}
\part Reading Assignment : Read the proof (Section 3.4, Theorem 3.21, Page 93)  of the claim : $\DTIME(2^{O(s(n))} \subseteq ASPACE(s(n))$. Determine an upper bound on the number of children for any universal configuration in the alternating Turing machine produced in the construction.
\part Conclude that $AL = \P$. Show that all $\CFL$s are in $\P$ by giving an alternating Turing machine running in $\log$ space for checking membership. (Assume that the $\CFL$ is given at the input in the $CNF$ form.).
\end{parts}

\question[10]
DeÔ¨Åne the language:
\[ \textrm{\sc ShortestPath} = {(G, k, s, t)| \textrm{ the shortest path from $s$ to $t$ in $G$ has length $k$} } \]
\begin{parts}
\part[5] Prove that {\sc ShortestPath} is in $\NL$.
\part[5] Prove that {\sc ShortestPath} is in $\L$ if and only if $\L = \NL$.
\end{parts}
\begin{solution}
\begin{parts}
 \part
 We can show {\sc ShortestPath} $\in \NL$ similar to the way we showed {\sc reach} $\in \NL$. At every vertex, non deterministically choose the next vertex
 which is the neighbour of the current vertex and the edge between current vertex and the neighbouring vertex is part of some shortest path from $s$ to $t$.
 Since, the outdegree of a vertex can be as bad as $n$, therefore, in the worst case $log (n) $ bits will be needed to make the non deterministic choice.
 Hence, {\sc ShortestPath} $\in \NL$
 
 \part
  $\L = \NL \implies$ {\sc ShortestPath} $\in \L$ \newline
  
   This direction is trivial from part a. Since {\sc ShortestPath} $\in \NL$ and $\L = \NL$, hence, {\sc ShortestPath} $\in \L$. \newline
  
  {\sc ShortestPath} $\in \L \implies \L = \NL$ \newline
   % Find a way to show shortestpath is NL-hard 
  \end{parts}
\end{solution}



\question[15]
An undirected graph is bipartite if its nodes can be divided into two sets such that all edges go from a node in one set to a node in the other set. Show that a graph is bipartite
if and only if it does not contain a cycle that contains an odd number of nodes. Let 
\[ \textrm{\sc Bipartite} =
\{ G \mid G \textrm{ is a bipartite graph } \} \] 
Show that {\sc Bipartite} is in $\NL$. (Hint : Use Immerman-Szelepsinyi theorem !).

\begin{solution}
\begin{parts}
\part
Bipartite graph $\implies$ graph contains no odd cycles. \newline

This can be shown by considering the contrapositive of the statement. If a graph contains odd cycles, then it is not bipartite. 
Consider any odd cycle $c_{1},c_{2}...c_{2n+1}$. To form a bipartite graph using these vertices, we have to select vertices in one set such that, no two of
them are adjacent in the cycle. Selecting set of vertices and forming two such sets, will leave out one vertex, for any combination. Hence such a set of vertices can never
be bipartite.\newline

Graph contains no odd cycles $\implies$ Bipartite graph  . \newline

Divide the set of vertices in the graph into set $A$ and $V \setminus A$. \newline
Every vertex $v \in A \Leftrightarrow $ the shortest path from every vertex in $A$ to $v$ is of odd length.

For such a construction of set, if there is no odd cycle, the graph is bipartite. Suppose there is no odd cycle, and let $v_{1}$ and $v_{2}$
both in $A$ be adjacent. Consider a vertex $v \in A$ . the length of the closed cycle from $v$ will be length of $v ... v_{1}$ + $v_{2} ... v$ + 1.
From the definition of set, this length is odd . (odd + odd + odd) . BUt our initial assumption was there is no odd cycle. Hence, there cannot be $v_{1}$
and $v_{2}$ in $A$ such that they are adjacent. Hence graph is bipartite.

\part
Consider the language $\overline{BIPARTITE}$ which is the complement of $BIPARTITE$. \newline
We can show that $\overline{BIPARTITE} \in \NL$ from the result in part(a). That is given a graph $G$, if there exists a odd cycle, then $G \in \overline{BIPARTITE}$.
Since, we already know {\sc Reach} $\in \NL$, we have to check if any of (G,$v_{1}$,$v_{1}$) ,(G,$v_{2}$,$v_{2}$) .. (G,$v_{n}$,$v_{n}$) is in {\sc Reach}.
This can also be done in log space because, we can reuse the same space of (G,$v_{1}$,$v_{1}$) for checking (G,$v_{2}$,$v_{2}$),...(G,$v_{n}$,$v_{n}$). \newline
Hence, $\overline{BIPARTITE}\in \NL$ and $BIPARTITE \in \co\NL$. \newline

From Immerman-Szelepsinyi Theorem, $\NL = \co\NL$. Hence, $BIPARTITE \in \NL$.
\end{parts}
\end{solution}


\question[25]
We define the product of two $n \times n$ Boolean matrices $A$ and $B$ as another $n \times n$ Boolean
matrix $C$ such that $C_{ij} = \bigvee_{k=1}^n (A_{ik} \land B_{kj})$.
\begin{parts}
\part[5] Show that boolean matrix multiplication can be done in logarithmic space.
\part[5] Using repeated squaring, argue that $A^p$ can be computed in space $O(\log n \log p)$.
\part[5] Show that if $A$ is the adjacency matrix of a graph, then $(A_{ij}^k = 1$ if and only if there
is a path of length at most $k$ from the vertex $i$ to vertex $j$ and is $0$ otherwise.
\part[5] Use the above to give an alternative proof that $\NL \subseteq \DSPACE(\log^2 n)$. We originally proved it using Savitch's theorem.
\end{parts}

\begin{solution}
 \begin{parts}
  \part
    To do boolean matrix multiplication, we need to store the indices $i$,$j$,$k$ and the current value of $A_{ik} \wedge B_{kj}$ .
    Since, each of $i$,$j$,$k$ can be atmost $n$, each of them require $\log (n)$ bits to represent. To store the current value we need 1 bit.
    Hence, to calculate the value of $C_{ij}$ we need $3 \log(n) + 1$ bits. This space can be reused for the calculations of all the entries in the matrix 
    $C$. Hence, the entire matrix multiplication of boolean values can be done in log space.
    \part
    Using the regular repeated squaring algorithm will require us to store the intermidiate matrices $A$,$A^{2}$,$A^{4}$.. But, each of them will require
    O($n$) and hence the overall space needed will become O($n$ $\log (p)$). Instead a slightly modified approach can be used. In the repeated squaring
    algorithm, whenever the $i,j$ th entry of $A^{r}$ for 1$\leqslant r \leqslant n$ is needed for the calculation, it is calculated seperately by invoking the 
    multiplication algorithm on $A^{r/2}$ and calculating the $i,j$ th entry of that matrix. Hence, atmost $\log (p)$ times that call will be made, and 
    $\log (p)$ bits needs to be stored. And each multiplication will take $\log (n)$ space which can be reused for successive multiplication. Hence, the total
    space needed will be O($\log (n) \log (p)$).
    
    \part
    This can be shown by using induction on length k. \newline
    Base: \newline
    The matrix $A$ contains entries which trivially indicates the existence of a path of length 1 between pair of vertices. i.e. if a edge exists
    between the vertices, there is a path of length 1. \newline
    Inductive case: \newline
    Let, $A^{k}$ ,$2 \leqslant k \leqslant n $ denote the entries such that if a path of length atmost k exists it is 1 , else 0. \newline
    $A^{k+1}$ = $A^{k} \ast A$ . \newline
    $A^{k+1}_{ij}$ is 1 if $A^{k}_{ir}$ is 1 and $A_{rj}$ is 1. This can alternatively be interpreted as, if there is a path of atmost length $k$ from vertex
    $i$ to $r$ and a path of length 1 from vertex $r$ to $j$. And the length of this path from $i$ to $j$ will be atmost $k$ + 1 . Hence, all the 1 entries in $A^{k+1}$
    indicate the pair of vertices having a atmost $k+1$ path between them.
    
    \part 
    From part (c), $A^{n}$ contains a 1 if there is a path of length atmost $n$. In a graph, if there exists a path between two vertices, then there exists
    a path of length of at most $n$ length between those two vertices (Pigeon hole principle). Hence, if $A^{n}_{ij}$ is 1 if and only if  $i$ is reachable from
    $j$.
    
    
 \end{parts}

 
 
\end{solution}




\end{questions}

%Add your answer like this.
%\begin{solution}
%
%\end{solution}

\end{document}
